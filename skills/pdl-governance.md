---
name: pdl-governance
description: Project Documentation List (PDL) governance workflow. Use when handling PDL Impact Assessment, creating PDL tracking tasks, performing gate reviews, or responding to assigned PDL tasks. Essential for Governance Agent and referenced by all agents handling compliance artefacts.
---

# PDL Governance

## Overview

The Project Documentation List (PDL) represents regulatory and audit artefacts required for compliance. This skill covers how to handle PDL in ASOM using the principle of **"Mapping Not Duplication"** - demonstrating controls exist via code, tests, and tools rather than creating redundant documentation.

## Core Principle

**PDL items must either be:**
1. **Produced** - Generated by SDLC process
2. **Referenced** - Exists in corporate system
3. **Not Applicable** - Explicitly justified exemption

## PDL Categories

### Initiation & Governance
- Project Charter (Epic/Demand context)
- Roadmap (Issue tracker roadmap)
- Risk Registry (Tracked risks)
- Quality Plan (Master plan reference)

### Architecture & Security
- Architecture Handbook (Confluence/docs)
- Security Assessment (FSA outcome)
- Privacy Impact (DPIA for PII)
- Third Party Assessment (Vendor reviews)

### Requirements
- User Requirements Specification (User Stories)
- Functional Specification (Acceptance Criteria)
- Design Specifications (Design docs)

### Testing (IQ/OQ/PQ)
- Test Strategy (Master strategy reference)
- IQ Evidence (Installation Qualification - unit/integration tests)
- OQ Evidence (Operational Qualification - business rule validation)
- PQ Evidence (Performance Qualification - UAT/performance tests)
- Traceability Matrix (Stories ↔ Tests)

### Release & Operations
- Change Request (CRQ record)
- IT Operational Handbook (ITOH - runbook)
- Service Transition (Deployment procedures)

## For Governance Agent

### PDL Impact Assessment Procedure

**When:** At epic creation and story refinement

**Steps:**

1. **Review scope** - Understand what's being built
2. **Identify impacts** - Which PDL categories affected?
3. **Determine action** - Produce, Reference, or N/A?
4. **Create tasks** - Track PDL work items
5. **Assign agents** - Route to appropriate specialist

**Template:**
```markdown
Epic: [Epic Title]

PDL Impact Assessment:

INITIATION & GOVERNANCE:
├─ Project Charter → [PRODUCED/REFERENCED/N/A]
│  └─ Action: [Create task / Link to existing / Justify N/A]
├─ Roadmap → [PRODUCED/REFERENCED/N/A]
│  └─ Action: [Create task / Link to existing / Justify N/A]
└─ Risk Registry → [PRODUCED/REFERENCED/N/A]
   └─ Action: [Create task / Link to existing / Justify N/A]

ARCHITECTURE & SECURITY:
├─ Architecture Handbook → [PRODUCED/REFERENCED/N/A]
│  └─ Action: [Create task / Link to existing / Justify N/A]
├─ Security Assessment → [PRODUCED/REFERENCED/N/A]
│  └─ Action: [Create task / Link to existing / Justify N/A]
└─ Privacy Impact → [PRODUCED/REFERENCED/N/A]
   └─ Action: [Create task / Link to existing / Justify N/A]

REQUIREMENTS:
├─ Functional Spec → PRODUCED (via acceptance criteria)
└─ User Requirements → PRODUCED (via user stories)

TESTING:
├─ Test Strategy → [PRODUCED/REFERENCED/N/A]
├─ IQ Evidence → PRODUCED (via TDD)
├─ OQ Evidence → [PRODUCED/REFERENCED/N/A]
│  └─ Action: [Create task if business rules need validation]
└─ Traceability Matrix → PRODUCED (auto-generated)

RELEASE:
└─ Change Request → PRODUCED (when ready for PROD)

OPERATIONS:
├─ ITOH → [PRODUCED/REFERENCED/N/A]
│  └─ Action: [Create task if ops procedures change]
└─ Service Transition → [PRODUCED/REFERENCED/N/A]

PDL Tasks Created: [List task IDs]
PDL Status: [% complete]
```

### PDL Task Creation

**Format:**
```
Task ID: T00X
Title: [Action] - [PDL Item] - [Context]
Type: PDL Task
Assigned: [Agent Role]
Epic: [Epic ID]
Story: [Story ID if applicable]
PDL Item: [PDL category]
Priority: [Based on deployment timeline]
```

**Examples:**
- T001: Update Risk Registry - PII Processing Risk
- T002: Document API Integration - Architecture Handbook
- T005: Create OQ Test Plan - Business Rule Validation

### PDL Gate Review (QA Deployment)

**Checklist:**
```markdown
QA Deployment Gate Review: Sprint [N]

REQUIREMENTS:
[ ] All user stories have acceptance criteria (Functional Spec)
[ ] Stories approved via workflow
[ ] Requirements traceable to business need

TESTING:
[ ] IQ evidence exists (test results, coverage reports)
[ ] OQ test plans executed (if required)
[ ] PQ tests executed (if required)
[ ] Traceability matrix generated and complete
[ ] Test summary reports available

ARCHITECTURE:
[ ] Architecture Handbook current (if architecture changed)
[ ] Design decisions documented
[ ] Integration points documented

SECURITY & PRIVACY:
[ ] Security assessment complete (if required)
[ ] Privacy impact assessment complete (if PII)
[ ] PII protection validated
[ ] Access controls verified

OPERATIONS:
[ ] ITOH updated (if operational procedures changed)
[ ] Monitoring and alerting documented
[ ] Troubleshooting procedures included

COMPLIANCE:
[ ] All PDL tasks complete
[ ] Audit logging verified
[ ] Data retention policies configured
[ ] No compliance violations

PDL Status: [X]% complete

DECISION: [APPROVE / HOLD / REJECT]
REASON: [If HOLD/REJECT, specify blocking items]
```

### PDL Gate Review (PROD Deployment)

**Additional Checks:**
```markdown
PROD Deployment Gate Review

RE-VALIDATION:
[ ] No architecture changes since QA
[ ] No new functionality added
[ ] PDL items still current

PROD-SPECIFIC:
[ ] IQ evidence for PROD environment
[ ] Change Request created and approved
[ ] Rollback procedures documented
[ ] PROD access controls configured
[ ] Production monitoring verified

FINAL COMPLIANCE:
[ ] All governance controls tested in QA
[ ] Audit trail complete
[ ] No compliance violations
[ ] Evidence archived for audit

DECISION: [APPROVE / REJECT]
Compliance Certificate: [ISSUED / WITHHELD]
```

## For BA Agent

### Handling PDL Tasks

**Common PDL Tasks:**
- Update Risk Registry
- Update Charter/Roadmap
- Clarify requirements for compliance

**Example: Update Risk Registry**
```markdown
Task: T001 - Update Risk Registry for PII Processing

Steps:
1. Identify new risks introduced by epic/story
2. Document risks with:
   - Description
   - Impact (High/Medium/Low)
   - Probability (High/Medium/Low)
   - Mitigation strategy
3. Link risks to epic/story in issue tracker
4. Tag with `pdl-risk` label
5. Notify Governance Agent for review
6. Mark task complete when approved
```

**Risk Documentation Format:**
```markdown
Risk ID: R00X
Epic: E001
Description: [What could go wrong]
Impact: [Consequence if it happens]
Probability: [Likelihood of occurrence]
Mitigation: [How we prevent/reduce it]
Owner: [Who's responsible]
Status: [Open/Mitigated/Accepted]
```

## For Dev Agent

### Handling PDL Tasks

**Common PDL Tasks:**
- Update Architecture Handbook
- Update ITOH (Operational Handbook)
- Create design documentation

**Example: Update Architecture Handbook**
```markdown
Task: T002 - Document API Integration

Steps:
1. Create/update architecture diagram
   - Show new components
   - Show data flows
   - Show integration points

2. Document in Confluence/docs:
   - Component description
   - Integration pattern
   - Authentication/authorization
   - Data format and schema
   - Error handling
   - Retry/timeout logic

3. Document architectural decisions:
   - Why this approach?
   - What alternatives considered?
   - What are tradeoffs?

4. Link to implementation:
   - Source code files
   - Configuration files
   - Tests

5. Tag Governance Agent for review
6. Mark task complete when approved
```

**Architecture Doc Template:**
```markdown
## [Component Name]

**Purpose**: [What it does]

**Integration Pattern**: [REST API / Event-driven / Batch / etc.]

**Data Flow**:
[Source] → [Processing] → [Destination]

**Authentication**: [Method and credential management]

**Key Design Decisions**:
- [Decision 1]: [Rationale]
- [Decision 2]: [Rationale]

**Configuration**:
- Location: [Config file path]
- Key parameters: [List important settings]

**Monitoring**:
- Metrics: [What to monitor]
- Alerts: [When to alert]

**Related Artefacts**:
- Code: [File paths]
- Tests: [Test file paths]
- Config: [Config file paths]
```

**Example: Update ITOH**
```markdown
Task: T006 - Add Monitoring Procedures for Customer API

Steps:
1. Document deployment:
   - Prerequisites
   - Step-by-step deployment
   - Verification steps
   - Rollback procedure

2. Document monitoring:
   - Key metrics to track
   - Normal operating ranges
   - Alert thresholds
   - Dashboard links

3. Document troubleshooting:
   - Common issues
   - Diagnostic steps
   - Resolution procedures
   - Escalation paths

4. Tag Governance Agent for review
5. Mark task complete when approved
```

**ITOH Template:**
```markdown
## [System/Component] Operations

### Deployment
**Prerequisites**:
- [What must be ready before deploy]

**Deployment Steps**:
1. [Step with command/action]
2. [Step with command/action]

**Verification**:
- [How to confirm success]

**Rollback**:
- [How to revert if needed]

### Monitoring
**Key Metrics**:
- [Metric name]: [Normal range] [Alert threshold]

**Dashboards**:
- [Dashboard name]: [Link]

**Alerts**:
- [Alert name]: [Condition] → [Action]

### Troubleshooting
**Issue: [Common problem]**
- Symptoms: [What you observe]
- Diagnosis: [How to confirm root cause]
- Resolution: [How to fix]
- Prevention: [How to avoid in future]
```

## For QA Agent

### Handling PDL Tasks

**Common PDL Tasks:**
- Create OQ Test Plan
- Generate Traceability Matrix
- Create Test Summary Reports

**Example: Create OQ Test Plan**
```markdown
Task: T005 - OQ Test Plan for Business Rules

Steps:
1. Identify business rules requiring validation
2. Create test cases for each rule:
   - Test case ID
   - Business rule being tested
   - Test inputs
   - Expected outputs
   - Pass/fail criteria

3. Execute tests in QA environment
4. Document results
5. Create OQ Evidence Report
6. Tag Governance Agent for review
7. Mark task complete when approved
```

**OQ Test Case Template:**
```markdown
## OQ Test Plan: [Feature Name]

**Purpose**: Validate business rules operate correctly

**Environment**: QA

**Test Cases**:

### OQ-001: [Business Rule Name]
**Rule**: [Statement of business logic]
**Input**: [Test data]
**Expected**: [Expected result]
**Actual**: [Actual result - fill during execution]
**Status**: [PASS/FAIL]

### OQ-002: [Edge Case]
**Rule**: [Boundary condition]
**Input**: [Edge case data]
**Expected**: [Expected behavior at boundary]
**Actual**: [Actual result]
**Status**: [PASS/FAIL]
```

**OQ Evidence Report Template:**
```markdown
## OQ Test Execution Report

**Date**: [Execution date]
**Environment**: QA
**Tester**: QA Agent

**Test Results**:
| Test ID | Description | Status | Notes |
|---------|-------------|--------|-------|
| OQ-001 | [Rule] | PASS | |
| OQ-002 | [Rule] | PASS | |
| OQ-003 | [Edge case] | PASS | |

**Summary**:
- Total test cases: [N]
- Passed: [N]
- Failed: [N]
- Coverage: [X]% of business rules

**Defects**: [List any issues found]

**Conclusion**: [Overall assessment]

**Evidence Location**: [Links to test results, screenshots, logs]
```

**Example: Generate Traceability Matrix**
```markdown
Task: T008 - Requirements Traceability Matrix

Steps:
1. Extract from issue tracker:
   - User Stories (requirements)
   - Test Cases
   - Links between them

2. Generate matrix showing:
   - Story → Tests mapping
   - IQ/OQ/PQ coverage
   - Gaps in coverage

3. Validate completeness:
   - Every story has tests
   - Every test traces to story
   - All IQ/OQ/PQ evidence exists

4. Export to docs/compliance/
5. Tag Governance Agent for review
6. Mark task complete when approved
```

**Traceability Matrix Template:**
```markdown
## Requirements Traceability Matrix - Sprint [N]

| Story | Requirement | Test Cases | IQ | OQ | PQ | Coverage |
|-------|-------------|------------|----|----|----|----|
| S001 | [Brief description] | TC-001, TC-002, TC-003 | ✓ | ✓ | N/A | 100% |
| S002 | [Brief description] | TC-004, TC-005 | ✓ | N/A | N/A | 100% |

**Legend**:
- IQ: Installation Qualification (unit/integration tests)
- OQ: Operational Qualification (business rule validation)
- PQ: Performance Qualification (UAT/performance tests)

**Coverage Summary**:
- Total Stories: [N]
- Total Test Cases: [N]
- IQ Coverage: [X]%
- OQ Coverage: [X]%
- Overall: [Complete/Incomplete]

**Gaps**: [List any stories without adequate test coverage]
```

## For Scrum Master

### PDL Tracking in Daily Coordination

**Include in Daily Updates:**
```markdown
## PDL Status

**Total PDL Tasks**: [N]
**Complete**: [N] ([X]%)
**In Progress**: [N]
**Blocked**: [N]

**Blocking Items**:
- [Task ID]: [Reason] - [Owner]

**Risk Assessment**:
- PDL completeness trend: [Improving/Stable/Declining]
- Risk to QA deployment: [Low/Medium/High]
- Days until QA gate: [N]
```

**PDL Impediment Handling:**
- Flag PDL tasks blocked >24 hours
- Escalate if PDL completion <70% at Day 7/14
- Coordinate with Governance on gate review timing

## PDL Task Labels/Tags

**Standard Labels:**
- `pdl-task` - All PDL tracking tasks
- `pdl-blocker` - Blocking QA/PROD deployment
- `pdl-architecture` - Architecture Handbook tasks
- `pdl-testing` - Test evidence tasks (IQ/OQ/PQ)
- `pdl-operations` - ITOH/runbook tasks
- `pdl-governance` - Assessment tasks
- `pdl-requirements` - Charter/risk/roadmap tasks

**Priority Levels:**
- `pdl-critical` - Must complete before QA
- `pdl-important` - Should complete before PROD
- `pdl-nice-to-have` - Can defer to next release

## Common Queries

**For Governance Agent:**
- "Show all incomplete PDL tasks for Sprint N"
- "Show PDL blockers"
- "PDL completeness percentage"

**For Scrum Master:**
- "Show PDL tasks by agent"
- "Show overdue PDL tasks"
- "PDL tasks at risk"

**For All Agents:**
- "Show my PDL tasks"
- "Show PDL tasks for story S001"

## Anti-Patterns

❌ **Creating PDL documents manually**
→ ✅ Generate from code, tests, and tools

❌ **Waiting until end of sprint for PDL**
→ ✅ Create PDL tasks at epic start

❌ **Governance doing all PDL work**
→ ✅ Distribute to appropriate agents

❌ **Treating PDL as separate from delivery**
→ ✅ Integrate into sprint backlog

❌ **Skipping PDL to "go faster"**
→ ✅ Will block deployment (slower overall)

## Success Metrics

- PDL tasks created at epic level: 100%
- PDL completeness at QA gate: 100%
- PDL-related deployment blocks: 0
- PDL tasks completed on time: >90%
- Audit findings related to missing PDL: 0

## Quick Reference

**Who does what:**
- Governance: PDL Impact Assessment, gate reviews, assessments
- BA: Risk register, charter, roadmap
- Dev: Architecture docs, ITOH, design specs
- QA: Test plans, test evidence, traceability
- Scrum Master: Track completion, flag blockers

**When:**
- Epic start: PDL Impact Assessment
- Story creation: Verify PDL coverage
- Throughout sprint: Complete PDL tasks
- QA gate: Validate 100% PDL completion
- PROD gate: Re-validate PDL + PROD checks

**Key principle:**
Mapping Not Duplication - demonstrate controls via existing artefacts
