# ASOM: Agentic Scrum Operating Model

An operating model for building production-quality data engineering and data science solutions using specialized agent roles, Scrum methodology, Test-Driven Development (TDD), and integrated governance through Project Documentation List (PDL) tracking.

## Overview

**ASOM (Agentic Scrum Operating Model)** enables you to work as a complete Scrum team by embodying specialized agent roles, with TDD as the foundation for quality and PDL governance ensuring audit-ready compliance.

The framework implements a complete Scrum team with specialized agent roles:
- **Business Analyst** - Requirements gathering, story refinement, and PDL artefacts (risk registry, roadmap)
- **Developer** - Implementation using strict TDD methodology (RED â†’ GREEN â†’ REFACTOR), architecture and operational documentation
- **QA** - Testing validation, quality assurance, and test evidence generation (IQ/OQ/PQ)
- **Governance** - PDL Gatekeeper ensuring compliance artefacts exist before QA/PROD deployment
- **Scrum Master** - Process facilitation, coordination, and PDL task tracking

All agents coordinate through an issue tracker (Beads or similar) for work management and PDL task tracking.

## Core Principles

### 1. Test-Driven Development (Fundamental)
TDD is not optional in ASOM - it's the foundation:
- **RED**: Write failing test first (defines requirements)
- **GREEN**: Write minimum code to pass (implements requirements)
- **REFACTOR**: Improve code quality (maintains standards)

Every story includes test requirements. Every implementation starts with tests. Tests serve as IQ/OQ evidence for compliance.

### 2. PDL Governance ("Mapping Not Duplication")
Project Documentation List (PDL) items are regulatory/audit artefacts that must exist:
- **Produced** - Generated by SDLC process (user stories, tests, architecture docs)
- **Referenced** - Exists in corporate system (master quality plan, test strategy)
- **Not Applicable** - Explicitly justified exemption

Governance Agent performs PDL Impact Assessment and creates tracking tasks assigned to appropriate agents. All PDL items must be complete before QA/PROD deployment.

### 3. Agentic Role Separation
Work divided among specialized roles with clear responsibilities, decision frameworks, and handoff protocols. Each agent handles specific PDL artefacts (BA: risk registry, Dev: architecture docs, QA: test evidence).

### 4. Scrum Methodology
Standard Scrum practices: sprints, ceremonies, Definition of Done, with PDL tracking integrated into workflow.

## Quick Start

### 1. Set Up Beads
```bash
# Install Beads (git-backed issue tracker for agent coordination)
# Follow Beads installation instructions for your environment
bd init
```

### 2. Load Agent Definitions
Each agent operates according to its AGENT.md file:
- `agents/BA-AGENT.md` - Business Analyst
- `agents/DEV-AGENT.md` - Developer
- `agents/QA-AGENT.md` - QA Specialist
- `agents/GOVERNANCE-AGENT.md` - Governance & Compliance
- `agents/SCRUM-MASTER-AGENT.md` - Scrum Master

### 3. Load Shared Skills
All agents reference these shared capabilities:
- `skills/beads-coordination.md` - Work tracking and handoffs
- `skills/python-data-engineering.md` - Python best practices
- `skills/snowflake-development.md` - Snowflake DDL, DML, optimization
- `skills/governance-requirements.md` - Compliance and security

### 4. Start Your First Sprint

As Product Owner (you), create the initial epic:
```bash
bd epic create "Customer Data Pipeline with Full Governance"
```

The agents will then follow ASOM with TDD:
1. **Governance Agent** - Creates PDL template and defines compliance requirements
2. **BA Agent** - Breaks down epic into stories WITH TEST REQUIREMENTS in acceptance criteria
3. **Scrum Master** - Facilitates sprint planning and tracks progress
4. **Dev Agent** - Implements stories using TDD (RED â†’ GREEN â†’ REFACTOR)
5. **QA Agent** - Validates TDD process was followed and runs additional tests
6. **Governance Agent** - Certifies compliance (tests prove controls work) and completes PDL

## Framework Structure

```
sdd-agent-framework/
â”œâ”€â”€ agents/                          # Agent role definitions
â”‚   â”œâ”€â”€ BA-AGENT.md                 # Business Analyst (requirements, risk registry)
â”‚   â”œâ”€â”€ DEV-AGENT.md                # Developer (TDD, architecture, ITOH)
â”‚   â”œâ”€â”€ QA-AGENT.md                 # QA (test validation, test evidence)
â”‚   â”œâ”€â”€ GOVERNANCE-AGENT.md         # Governance (PDL gatekeeper)
â”‚   â””â”€â”€ SCRUM-MASTER-AGENT.md       # Scrum Master (coordination, PDL tracking)
â”‚
â”œâ”€â”€ skills/                          # Shared capabilities
â”‚   â”œâ”€â”€ beads-coordination.md       # Work tracking
â”‚   â”œâ”€â”€ python-data-engineering.md  # Python patterns
â”‚   â”œâ”€â”€ snowflake-development.md    # Snowflake best practices
â”‚   â”œâ”€â”€ governance-requirements.md  # Compliance requirements
â”‚   â””â”€â”€ pdl-governance.md           # PDL workflow and tracking
â”‚
â”œâ”€â”€ ASOM.md                          # Framework philosophy and TDD principles
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ CLAUDE.md                        # Meta-coordinator for agent orchestration
â”œâ”€â”€ QUICKSTART.md                    # Your first sprint guide
â”œâ”€â”€ ARCHITECTURE.md                  # Design philosophy (AGENT vs SKILLS)
â””â”€â”€ PDL-REFERENCE.md                 # PDL quick reference for humans
```

## Agent Roles & Responsibilities

### Business Analyst
**Purpose**: Translate business needs into clear technical requirements

**Key Activities**:
- Analyze epics and create user stories
- Define acceptance criteria including governance requirements
- Document data sources and business rules
- Coordinate with Governance Agent on compliance needs

**Handoff**: BA â†’ Dev (stories marked "ready")

### Developer
**Purpose**: Build production-quality data pipelines and transformations

**Key Activities**:
- Implement Python data extraction/transformation logic
- Create Snowflake schemas and SQL
- Write comprehensive tests (unit & integration)
- Implement governance controls (PII masking, audit logging)

**Handoff**: Dev â†’ QA (PR created with tests)

### QA
**Purpose**: Ensure quality meets acceptance criteria and governance standards

**Key Activities**:
- Execute functional and data quality tests
- Validate governance controls actually work
- Perform code reviews
- Report defects with reproduction steps

**Handoff**: QA â†’ Governance (all tests passing)

### Governance
**Purpose**: Ensure compliance, security, and audit-readiness

**Key Activities**:
- Define compliance requirements for sprint
- Validate PII protection mechanisms
- Verify access controls and audit trails
- Generate compliance documentation (PDL)

**Handoff**: Governance â†’ Done (compliance certified)

### Scrum Master
**Purpose**: Facilitate process and remove impediments

**Key Activities**:
- Coordinate agent handoffs
- Track sprint progress and burndown
- Identify and resolve blockers
- Facilitate retrospectives and improvements

**Handoff**: Coordinates all other handoffs

## Workflow

### Typical Story Lifecycle

```
1. Epic Created (PO)
   â””â”€ Governance Agent: PDL Impact Assessment
      â”œâ”€ Creates PDL tasks (T001-T00N)
      â””â”€ Assigns to appropriate agents

2. BA Agent: Creates stories from epic
   â”œâ”€ Defines acceptance criteria
   â”œâ”€ Includes test requirements (TDD)
   â”œâ”€ Documents data sources
   â”œâ”€ Handles PDL tasks (e.g., T001: Update Risk Registry)
   â””â”€ Status: "refined"

3. Governance Agent: Reviews for compliance
   â”œâ”€ Adds governance requirements
   â”œâ”€ Validates PDL tasks created
   â””â”€ Status: "ready"

4. Dev Agent: Implements solution using TDD
   â”œâ”€ RED: Writes failing tests
   â”œâ”€ GREEN: Implements code to pass tests
   â”œâ”€ REFACTOR: Improves code quality
   â”œâ”€ Handles PDL tasks (e.g., T002: Update Architecture Handbook)
   â””â”€ Status: "in-review" (PR created)

5. QA Agent: Validates implementation
   â”œâ”€ Verifies TDD process followed
   â”œâ”€ Executes test plan
   â”œâ”€ Validates data quality and governance controls
   â”œâ”€ Handles PDL tasks (e.g., T005: Create OQ Test Evidence)
   â””â”€ Status: "testing" â†’ "governance-review"

6. Governance Agent: PDL Gate Review
   â”œâ”€ Validates ALL PDL tasks complete (100%)
   â”œâ”€ Verifies compliance controls work
   â”œâ”€ Checks architecture docs current
   â”œâ”€ Confirms test evidence exists (IQ/OQ/PQ)
   â””â”€ DECISION: APPROVE/HOLD/REJECT QA deployment

7. QA Deployment (if approved)
   â””â”€ System deployed to QA for validation

8. Governance Agent: PROD Gate Review
   â”œâ”€ Re-validates PDL completeness
   â”œâ”€ Confirms no changes since QA
   â”œâ”€ Validates PROD-specific items (Change Request, etc.)
   â””â”€ DECISION: APPROVE/REJECT PROD deployment

9. Story Complete
   â””â”€ Status: "done" (all PDL artefacts exist and current)
```

### Communication Pattern

All agents communicate through Beads comments with structured format:
```
[Agent Name] Action taken

Context/Reasoning:
- Why this approach
- Alternatives considered
- Dependencies

Progress:
- âœ… Completed
- ğŸš§ In progress
- â³ Pending

Next steps:
- Planned actions
- Needed from others
```

## Governance Framework

### PII Protection
- **Email**: SHA256 hash with salt â†’ deterministic tokens
- **Phone**: Redaction â†’ XXX-XXX-1234 format
- **SSN/NI**: Remove entirely or hash
- **Addresses**: City level only or remove

### Access Control (RBAC)
```
Raw Layer (PII)        â†’ DATA_ENGINEER only
Curated Layer (masked) â†’ ANALYST roles
Analytics Layer (agg)  â†’ BUSINESS_USER
```

### Audit Requirements
- All curated tables: `_audit_user`, `_audit_timestamp`
- Access logs: 7 years retention
- Modification logs: 7 years retention

### Data Retention
- Raw (PII): 30 days (automated deletion)
- Curated: 2 years
- Analytics: 5 years
- Audit logs: 7 years minimum

## Technology Stack

### Python
- **polars** - High-performance DataFrames
- **pydantic** - Data validation
- **pytest** - Testing (generates IQ evidence)
- **snowflake-connector-python** - Snowflake integration

### Snowflake
- **Medallion Architecture** - Bronze â†’ Silver â†’ Gold
- **Streams & Tasks** - Near-real-time processing
- **Row-level security** - Fine-grained access control
- **Resource monitors** - Cost management

### Coordination & Governance
- **Issue Tracker** - Work and PDL task tracking (Beads, Jira, or similar)
- **Documentation** - Architecture and operational handbooks (Confluence, Markdown, or similar)
- **Test Management** - Test evidence tracking (XRay, issue tracker, or similar)

## Sprint 0: Bootstrap

Before Sprint 1, you'll need to:

1. **Set up issue tracking workspace**
   ```bash
   # Example with Beads
   bd init
   bd epic create "Establish ASOM Capability"
   
   # Or configure your issue tracker of choice
   ```

2. **Configure environments**
   - Snowflake: DEV, TEST, PROD databases
   - Python: Virtual environment with dependencies
   - Secrets: AWS Secrets Manager / Azure Key Vault

3. **Define initial governance policies**
   - Data classification standards
   - PII masking requirements
   - Access control roles
   - Retention policies
   - PDL artefact requirements

4. **Set up PDL tracking**
   - Define PDL categories for your organization
   - Create PDL task labels/tags in issue tracker
   - Establish PDL completeness gates for QA/PROD
   - Document PDL-to-artefact mappings

## Sprint 1: Prove the Model

**Goal**: Build a single data pipeline with full governance to prove the agent team works

**Example Epic**: "Customer Data Ingestion Pipeline with PII Governance"

**Expected Stories**:
- Extract customer data from REST API
- Implement PII masking (email, phone)
- Create Snowflake schema (bronze â†’ silver â†’ gold)
- Implement data quality checks
- Set up access controls
- Create audit logging
- Configure retention policies

**Success Criteria**:
- Pipeline works end-to-end âœ…
- PII properly protected âœ…
- All tests passing (IQ evidence) âœ…
- OQ test evidence created âœ…
- Governance documentation complete âœ…
- **All PDL tasks complete (100%)** âœ…
- All agent handoffs successful âœ…
- <50% manual intervention required

## Monitoring & Metrics

### Sprint Health
- **Velocity**: Story points completed per sprint
- **Burndown**: Daily remaining work tracking
- **Quality**: Defects found, test coverage
- **Governance**: Violations, compliance gaps
- **PDL Completeness**: % of PDL tasks complete

### Agent Performance
- **BA**: Story refinement turnaround, PDL task completion (risk registry)
- **Dev**: Code quality, test coverage, PDL task completion (architecture, ITOH)
- **QA**: Defect detection rate, PDL task completion (test evidence)
- **Governance**: Time to validate compliance, PDL gate review efficiency
- **Scrum Master**: Impediment resolution time, PDL tracking visibility

### Example Dashboard
```
Sprint 1 (Day 7/14):
â”œâ”€ Committed: 40 points
â”œâ”€ Completed: 24 points
â”œâ”€ Remaining: 16 points
â”œâ”€ On track: âœ… Yes
â”œâ”€ Defects: 2 (minor)
â”œâ”€ Governance: 0 violations
â”œâ”€ PDL Completeness: 75% (6/8 tasks complete)
â”‚  â”œâ”€ T001: Risk Registry âœ…
â”‚  â”œâ”€ T002: Architecture Doc (in progress)
â”‚  â””â”€ T006: ITOH (not started - flagged)
â””â”€ Impediments: 1 (PDL task blocked on PO decision)
```

## Phased Autonomy

### Phase 1: Supervised (Weeks 1-4)
- Agents produce work but don't commit
- You review all artifacts
- Approve/reject with feedback
- Goal: Build trust and tune agents

### Phase 2: Conditional (Weeks 5-8)
- Low-risk: Automated (story updates, tests)
- Medium-risk: Approval needed (merges, schemas)
- High-risk: Supervised (compliance, security)
- Goal: Reduce manual intervention

### Phase 3: Full Autonomy (Week 9+)
- Agents operate independently
- Exception-based oversight
- Automated quality gates
- Goal: Minimal human intervention

## Troubleshooting

### Agents Not Coordinating
- Check Beads status transitions
- Review comment format in stories
- Verify agents following handoff protocol

### Quality Issues
- Review test coverage metrics
- Check if QA validating acceptance criteria
- Verify governance controls actually tested

### Governance Violations
- Escalate to Governance Agent immediately
- Document in issue tracker
- Update controls in skills/governance-requirements.md

### Sprint Goals Not Met
- Review retrospective for root causes
- Check impediment resolution times
- Adjust story sizing or capacity

## Extending the Framework

### Add New Agent Roles
Create `agents/NEW-ROLE-AGENT.md` following the pattern:
- Role Identity
- Core Responsibilities
- Working with Other Agents
- Skills & Capabilities
- Decision-Making Framework

### Add New Skills
Create `skills/new-skill.md` with:
- Frontmatter (name, description)
- Practical guidance and examples
- Best practices
- Common patterns

### Customize for Your Domain
- Update PII protection for your data types
- Add domain-specific data quality rules
- Customize governance for your regulations
- Add organization-specific patterns

## Best Practices

1. **Start Small**: Single pipeline first, scale after proving model
2. **Trust but Verify**: Phase autonomy gradually
3. **Clear Handoffs**: Explicit status transitions in Beads
4. **Document Decisions**: Use ADRs for significant choices
5. **Test Governance**: Verify controls actually work
6. **Iterate**: Retrospectives drive continuous improvement
7. **Measure**: Track velocity, quality, compliance metrics
8. **Automate**: Use Snowflake tasks for retention, testing
9. **Communicate**: Structured comments in Beads
10. **Maintain**: Update agent definitions based on learnings

## Support & Contribution

This framework is designed to evolve through use. Update agent definitions and skills based on retrospective findings and lessons learned.

## License

This framework is provided as-is for use in autonomous agent-based development projects.
